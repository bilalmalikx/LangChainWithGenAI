{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2754069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleGENAI app using langchain\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "\n",
    "# Step 3: Setup LangSmith Tracer\n",
    "from langsmith import traceable\n",
    "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
    "tracer = LangChainTracer()\n",
    "# Step 4: Use LangChain with OpenAI + LangSmith\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6de1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# data ingestion form the website we need to scrape the data\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725dd0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x1272d0150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://platform.openai.com/docs/api-reference/introduction\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4bdc40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://platform.openai.com/docs/api-reference/introduction', 'language': 'No language found.'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEnable JavaScript and cookies to continue\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a46c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://platform.openai.com/docs/api-reference/introduction', 'language': 'No language found.'}, page_content='Enable JavaScript and cookies to continue')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load our data\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d6f06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings=OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4996314d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x127ff46d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectordb=FAISS.from_documents(documents,embeddings)\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12d99a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Enable JavaScript and cookies to continue'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"This API reference describes the RESTful, streaming, and realtime APIs you can use to interact with the OpenAI platform\"\n",
    "result=vectordb.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11967ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\n    Answer the question based on the provided context:\\n    <context>\\n    {context}\\n    </context>\\n\\n    Question: {input}\\n    '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x131ada550>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x131adb4d0>, root_client=<openai.OpenAI object at 0x131ada290>, root_async_client=<openai.AsyncOpenAI object at 0x131adb110>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. Initialize tracer\n",
    "tracer = LangChainTracer()\n",
    "\n",
    "# 2. Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# 3. Create prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the question based on the provided context:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \n",
    "    Question: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 4. Create document chain (LLM + Prompt)\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b022ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and realtime APIs you can use to interact with the OpenAI platform.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "    \"input\":\"This API reference describes the RESTful, streaming\",\n",
    "    \"context\":[Document(page_content=(\"This API reference describes the RESTful, streaming, and realtime APIs you can use to interact with the OpenAI platform\"))]\n",
    "    }\n",
    "    , config={\"callbacks\": [tracer]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea8d9909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x16b6f1010>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriver\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25b67cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriver\n",
    "retriever=vectordb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66ab8084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x16b6f1010>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\n    Answer the question based on the provided context:\\n    <context>\\n    {context}\\n    </context>\\n\\n    Question: {input}\\n    '), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x16b916690>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x16b917310>, root_client=<openai.OpenAI object at 0x16b9094d0>, root_async_client=<openai.AsyncOpenAI object at 0x16b915350>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4afef665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unfortunately, the context provided is insufficient to fully describe or answer the question regarding the RESTful streaming API reference. Generally, a RESTful API is a design pattern for interacting with web services where resources are identified by URLs and verbs like GET, POST, PUT, and DELETE are used for operations. Streaming refers to a data transport design where data is delivered in a continuous flow, allowing real-time updates.\\n\\nPlease provide more detailed context or specify the question further for an accurate response.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retriever_chain.invoke({\"input\": \"This API reference describes the RESTful, streaming\"})\n",
    "response['answer']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
